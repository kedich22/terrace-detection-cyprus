{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for geospatial processing and segmentation\n",
    "import os\n",
    "import random\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Segmentation and vectorization libraries\n",
    "from skimage import segmentation as seg\n",
    "from rsgislib.vectorutils.createvectors import polygonise_raster_to_vec_lyr\n",
    "\n",
    "# Geospatial utilities\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "import simplekml\n",
    "\n",
    "print(\"All required libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyprus Terrace Detection: Image Segmentation Pipeline\n",
    "\n",
    "This notebook performs automated image segmentation across the entire Cyprus island using SLIC (Simple Linear Iterative Clustering) algorithm. The workflow includes:\n",
    "\n",
    "- **Grid-based processing**: Divides Cyprus into polygon grids\n",
    "- **Adaptive segmentation**: Calculates optimal segment density based on area\n",
    "- **Multi-format output**: Generates both raster and vector segment representations\n",
    "- **Automated vectorization**: Converts segments to polygon geometries for analysis\n",
    "\n",
    "**Key Parameters:**\n",
    "- Segmentation density: ~47.7 segments per km² (optimized for 10m resolution imagery)\n",
    "- SLIC compactness: 1 (balanced between spatial and color similarity)\n",
    "- Gaussian smoothing: σ=2 (noise reduction before segmentation)\n",
    "\n",
    "**Outputs:**\n",
    "- Individual polygon segment files in EPSG:32636 (UTM Zone 36N)\n",
    "- Merged dataset for island-wide analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Configuration\n",
    "\n",
    "Verify input data and set up processing parameters for island-wide segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:3857\n"
     ]
    }
   ],
   "source": [
    "# Configuration: Input data paths and parameters\n",
    "BASE_RASTER_FILE = \"all_cyprus3857.tif\"  # Full Cyprus imagery in Web Mercator\n",
    "GRID_POLYGONS_FILE = \"grid_Cyprus.gpkg\"  # Processing grid polygons\n",
    "OUTPUT_DIRECTORY = \"CyprusMap/polygons_all\"  # Output directory for segmented polygons\n",
    "\n",
    "# Segmentation parameters (optimized for terrace detection)\n",
    "SEGMENTS_PER_KM2 = 47.658  # Segment density for EPSG:3857 projection\n",
    "SLIC_COMPACTNESS = 1       # Balance between color/spatial similarity\n",
    "GAUSSIAN_SIGMA = 2         # Noise reduction parameter\n",
    "TARGET_CRS = \"EPSG:32636\"  # UTM Zone 36N for Cyprus\n",
    "\n",
    "# Verify input raster properties\n",
    "with rasterio.open(BASE_RASTER_FILE) as src:\n",
    "    print(\"=== INPUT RASTER PROPERTIES ===\")\n",
    "    print(f\"Coordinate Reference System: {src.crs}\")\n",
    "    print(f\"Raster dimensions: {src.width} x {src.height} pixels\")\n",
    "    print(f\"Number of bands: {src.count}\")\n",
    "    print(f\"Data type: {src.dtypes[0]}\")\n",
    "    print(f\"Pixel size: {src.transform[0]:.2f} x {abs(src.transform[4]):.2f} meters\")\n",
    "\n",
    "print(f\"\\n=== SEGMENTATION CONFIGURATION ===\")\n",
    "print(f\"Target segment density: {SEGMENTS_PER_KM2} segments/km²\")\n",
    "print(f\"SLIC compactness factor: {SLIC_COMPACTNESS}\")\n",
    "print(f\"Gaussian smoothing sigma: {GAUSSIAN_SIGMA}\")\n",
    "print(f\"Output CRS: {TARGET_CRS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processing grid and verify structure\n",
    "grid_polygons = gpd.read_file(GRID_POLYGONS_FILE)\n",
    "\n",
    "print(\"=== PROCESSING GRID PROPERTIES ===\")\n",
    "print(f\"Number of grid polygons: {len(grid_polygons)}\")\n",
    "print(f\"Grid CRS: {grid_polygons.crs}\")\n",
    "print(f\"Total coverage area: {grid_polygons.geometry.area.sum() / 1e6:.2f} km²\")\n",
    "print(f\"Average grid cell area: {grid_polygons.geometry.area.mean() / 1e6:.2f} km²\")\n",
    "\n",
    "# Show column structure\n",
    "print(f\"\\nGrid polygon columns: {list(grid_polygons.columns)}\")\n",
    "print(\"Grid data structure verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid-Based SLIC Segmentation\n",
    "\n",
    "Process each grid polygon individually using adaptive SLIC segmentation based on area-optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_polygon_segmentation(polygon_data, polygon_index, base_raster_path, output_base_dir):\n",
    "    \"\"\"\n",
    "    Process a single polygon through SLIC segmentation pipeline.\n",
    "    \n",
    "    Args:\n",
    "        polygon_data: Single polygon geometry from GeoDataFrame\n",
    "        polygon_index (int): Index of the polygon for naming\n",
    "        base_raster_path (str): Path to the base raster file\n",
    "        output_base_dir (str): Base output directory\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing statistics and output paths\n",
    "    \"\"\"\n",
    "    # Create output directory for this polygon\n",
    "    polygon_output_dir = os.path.join(output_base_dir, f\"polygon_{polygon_index}\")\n",
    "    os.makedirs(polygon_output_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Clip raster to polygon bounds\n",
    "    with rasterio.open(base_raster_path) as src:\n",
    "        clipped_raster, clipped_transform = mask(src, [polygon_data.geometry], crop=True)\n",
    "        clipped_profile = src.profile.copy()\n",
    "\n",
    "    # Update profile for clipped raster\n",
    "    clipped_profile.update({\n",
    "        \"height\": clipped_raster.shape[1],\n",
    "        \"width\": clipped_raster.shape[2],\n",
    "        \"transform\": clipped_transform\n",
    "    })\n",
    "\n",
    "    # Step 2: Calculate optimal number of segments based on area\n",
    "    pixel_area = abs(clipped_profile['transform'][0] * clipped_profile['transform'][4])\n",
    "    total_area_m2 = pixel_area * clipped_raster.shape[1] * clipped_raster.shape[2]\n",
    "    area_km2 = total_area_m2 / 1e6\n",
    "    \n",
    "    optimal_segments = max(10, round(SEGMENTS_PER_KM2 * area_km2))  # Minimum 10 segments\n",
    "\n",
    "    # Step 3: Perform SLIC segmentation\n",
    "    # Transpose raster from (bands, height, width) to (height, width, bands) for scikit-image\n",
    "    image_for_segmentation = clipped_raster.transpose(1, 2, 0)\n",
    "    \n",
    "    segmented_image = seg.slic(\n",
    "        image=image_for_segmentation,\n",
    "        n_segments=optimal_segments,\n",
    "        compactness=SLIC_COMPACTNESS,\n",
    "        sigma=GAUSSIAN_SIGMA,\n",
    "        start_label=1,\n",
    "        max_num_iter=100,\n",
    "        convert2lab=True,\n",
    "        enforce_connectivity=True,\n",
    "        min_size_factor=0.5,\n",
    "        max_size_factor=3,\n",
    "        slic_zero=True\n",
    "    )\n",
    "\n",
    "    # Step 4: Save segmented raster (temporary)\n",
    "    temp_segments_raster = os.path.join(\n",
    "        polygon_output_dir, \n",
    "        f\"segments_no{polygon_index}_{optimal_segments}_temp.tif\"\n",
    "    )\n",
    "    \n",
    "    segment_profile = clipped_profile.copy()\n",
    "    segment_profile.update({\n",
    "        'count': 1, \n",
    "        'compress': 'lzw', \n",
    "        'dtype': 'uint32', \n",
    "        'driver': 'GTiff', \n",
    "        'BIGTIFF': 'YES'\n",
    "    })\n",
    "    \n",
    "    with rasterio.open(temp_segments_raster, 'w', **segment_profile) as dst:\n",
    "        dst.write(segmented_image, 1)\n",
    "\n",
    "    # Step 5: Vectorize segments to polygons\n",
    "    temp_vector_path = os.path.join(\n",
    "        polygon_output_dir, \n",
    "        f\"segments_no{polygon_index}_temp.gpkg\"\n",
    "    )\n",
    "    \n",
    "    polygonise_raster_to_vec_lyr(\n",
    "        out_vec_file=temp_vector_path,\n",
    "        out_vec_lyr=\"segments\",\n",
    "        out_format=\"GPKG\",\n",
    "        input_img=temp_segments_raster,\n",
    "        img_band=1,\n",
    "        mask_img=temp_segments_raster,\n",
    "        mask_band=1\n",
    "    )\n",
    "\n",
    "    # Step 6: Reproject to target CRS and add attributes\n",
    "    segments_vector = gpd.read_file(temp_vector_path)\n",
    "    segments_reprojected = segments_vector.to_crs(TARGET_CRS)\n",
    "    \n",
    "    # Add processing metadata\n",
    "    segments_reprojected['grid_id'] = polygon_index\n",
    "    segments_reprojected['selected'] = 0  # Default selection status\n",
    "    segments_reprojected['area_m2'] = segments_reprojected.geometry.area\n",
    "    segments_reprojected['n_segments'] = optimal_segments\n",
    "    \n",
    "    # Step 7: Save final output\n",
    "    final_output_path = os.path.join(\n",
    "        polygon_output_dir, \n",
    "        f\"Segments_no{polygon_index}_proj.gpkg\"\n",
    "    )\n",
    "    segments_reprojected.to_file(final_output_path, driver=\"GPKG\")\n",
    "\n",
    "    # Step 8: Clean up temporary files\n",
    "    os.remove(temp_segments_raster)\n",
    "    os.remove(temp_vector_path)\n",
    "\n",
    "    return {\n",
    "        'polygon_id': polygon_index,\n",
    "        'area_km2': area_km2,\n",
    "        'n_segments': optimal_segments,\n",
    "        'n_final_segments': len(segments_reprojected),\n",
    "        'output_path': final_output_path\n",
    "    }\n",
    "\n",
    "# Main processing loop\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING CYPRUS-WIDE SEGMENTATION PROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "processing_stats = []\n",
    "total_polygons = len(grid_polygons)\n",
    "\n",
    "for polygon_idx, (_, polygon_row) in enumerate(grid_polygons.iterrows(), 1):\n",
    "    print(f\"\\nProcessing polygon {polygon_idx}/{total_polygons}...\")\n",
    "    \n",
    "    try:\n",
    "        stats = process_polygon_segmentation(\n",
    "            polygon_data=polygon_row,\n",
    "            polygon_index=polygon_idx,\n",
    "            base_raster_path=BASE_RASTER_FILE,\n",
    "            output_base_dir=OUTPUT_DIRECTORY\n",
    "        )\n",
    "        \n",
    "        processing_stats.append(stats)\n",
    "        \n",
    "        print(f\"  ✓ Area: {stats['area_km2']:.2f} km²\")\n",
    "        print(f\"  ✓ Target segments: {stats['n_segments']}\")\n",
    "        print(f\"  ✓ Final segments: {stats['n_final_segments']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error processing polygon {polygon_idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Summary statistics\n",
    "total_area = sum(s['area_km2'] for s in processing_stats)\n",
    "total_segments = sum(s['n_final_segments'] for s in processing_stats)\n",
    "avg_density = total_segments / total_area if total_area > 0 else 0\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"SEGMENTATION PROCESSING COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Processed polygons: {len(processing_stats)}/{total_polygons}\")\n",
    "print(f\"Total area processed: {total_area:.2f} km²\")\n",
    "print(f\"Total segments created: {total_segments:,}\")\n",
    "print(f\"Average segment density: {avg_density:.1f} segments/km²\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Integration and Final Output\n",
    "\n",
    "Merge all individual polygon segments into a comprehensive island-wide dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_segmentation_results(input_directory, output_file_path):\n",
    "    \"\"\"\n",
    "    Merge all individual polygon segmentation results into a single comprehensive dataset.\n",
    "    \n",
    "    Args:\n",
    "        input_directory (str): Directory containing individual polygon segment files\n",
    "        output_file_path (str): Path for the merged output file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Merge statistics and information\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"MERGING SEGMENTATION RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Discover all segment files\n",
    "    segment_files = []\n",
    "    for root, dirs, filenames in os.walk(input_directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.gpkg') and 'Segments_no' in filename:\n",
    "                segment_files.append(os.path.join(root, filename))\n",
    "    \n",
    "    print(f\"Found {len(segment_files)} segment files to merge\")\n",
    "    \n",
    "    if not segment_files:\n",
    "        print(\"No segment files found for merging!\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Load and merge all segment files\n",
    "    print(\"Loading and merging segment files...\")\n",
    "    merged_segments = gpd.GeoDataFrame()\n",
    "    \n",
    "    merge_stats = {\n",
    "        'files_processed': 0,\n",
    "        'total_segments': 0,\n",
    "        'files_with_errors': 0,\n",
    "        'area_coverage_km2': 0\n",
    "    }\n",
    "    \n",
    "    for file_path in segment_files:\n",
    "        try:\n",
    "            # Load individual segment file\n",
    "            segments = gpd.read_file(file_path)\n",
    "            \n",
    "            # Add file identifier\n",
    "            polygon_id = os.path.basename(os.path.dirname(file_path)).replace('polygon_', '')\n",
    "            segments['source_polygon'] = polygon_id\n",
    "            \n",
    "            # Merge with main dataset\n",
    "            merged_segments = pd.concat([merged_segments, segments], ignore_index=True)\n",
    "            \n",
    "            # Update statistics\n",
    "            merge_stats['files_processed'] += 1\n",
    "            merge_stats['total_segments'] += len(segments)\n",
    "            \n",
    "            if 'area_m2' in segments.columns:\n",
    "                merge_stats['area_coverage_km2'] += segments['area_m2'].sum() / 1e6\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error processing {file_path}: {e}\")\n",
    "            merge_stats['files_with_errors'] += 1\n",
    "            continue\n",
    "    \n",
    "    # Step 3: Data quality checks and cleanup\n",
    "    print(\"Performing data quality checks...\")\n",
    "    \n",
    "    # Remove any invalid geometries\n",
    "    initial_count = len(merged_segments)\n",
    "    merged_segments = merged_segments[merged_segments.geometry.is_valid]\n",
    "    invalid_removed = initial_count - len(merged_segments)\n",
    "    \n",
    "    if invalid_removed > 0:\n",
    "        print(f\"  Removed {invalid_removed} invalid geometries\")\n",
    "    \n",
    "    # Add unique segment ID\n",
    "    merged_segments['segment_id'] = range(1, len(merged_segments) + 1)\n",
    "    \n",
    "    # Ensure proper CRS\n",
    "    if merged_segments.crs != TARGET_CRS:\n",
    "        print(f\"  Reprojecting to {TARGET_CRS}\")\n",
    "        merged_segments = merged_segments.to_crs(TARGET_CRS)\n",
    "    \n",
    "    # Calculate final area statistics if not present\n",
    "    if 'area_m2' not in merged_segments.columns:\n",
    "        merged_segments['area_m2'] = merged_segments.geometry.area\n",
    "        merge_stats['area_coverage_km2'] = merged_segments['area_m2'].sum() / 1e6\n",
    "    \n",
    "    # Step 4: Save merged dataset\n",
    "    print(f\"Saving merged dataset to: {output_file_path}\")\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    merged_segments.to_file(output_file_path, driver=\"GPKG\")\n",
    "    \n",
    "    # Final statistics\n",
    "    merge_stats['final_segments'] = len(merged_segments)\n",
    "    merge_stats['output_file'] = output_file_path\n",
    "    \n",
    "    return merge_stats\n",
    "\n",
    "# Execute merging process\n",
    "MERGED_OUTPUT_FILE = \"Saga_new_data/Cyprus_complete_segments.gpkg\"\n",
    "\n",
    "merge_results = merge_segmentation_results(\n",
    "    input_directory=OUTPUT_DIRECTORY,\n",
    "    output_file_path=MERGED_OUTPUT_FILE\n",
    ")\n",
    "\n",
    "if merge_results:\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"MERGING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Files processed: {merge_results['files_processed']}\")\n",
    "    print(f\"Files with errors: {merge_results['files_with_errors']}\")\n",
    "    print(f\"Total segments: {merge_results['final_segments']:,}\")\n",
    "    print(f\"Coverage area: {merge_results['area_coverage_km2']:.2f} km²\")\n",
    "    print(f\"Average segment size: {merge_results['area_coverage_km2']*1e6/merge_results['final_segments']:.0f} m²\")\n",
    "    print(f\"Output file: {merge_results['output_file']}\")\n",
    "    print(\"=\" * 50)\n",
    "else:\n",
    "    print(\"Merging process failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osgeo-env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
