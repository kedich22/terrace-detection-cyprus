{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyprus Terrace Detection - Model Training\n",
    "Two-stage classification: (1) Binary terrace detection, (2) Multiclass terrace type classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, roc_curve, roc_auc_score, auc,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    balanced_accuracy_score, matthews_corrcoef\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set working directory\n",
    "working_directory = \"C:/Users/u0148406/OneDrive - KU Leuven/PhD KUL/TerraceDetection\"\n",
    "os.chdir(working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_grid(data, percentage_validation=0.2, random_state=None, landcover=False):\n",
    "    \"\"\"Spatial train-test split based on grid numbers to avoid spatial autocorrelation\"\"\"\n",
    "    data['unique_id'] = data.reset_index().index\n",
    "    data = data[data['terrace'].isin([0, 1])]\n",
    "\n",
    "    rows_select = round(percentage_validation * data.shape[0])\n",
    "    data_select = data[data['selected'] == 1]\n",
    "    valid_no_pergrid = round(np.mean(data_select['gridnumber'].value_counts()))\n",
    "    grid_no = round(rows_select / valid_no_pergrid) - 1\n",
    "    \n",
    "    gridnumbers = pd.Series(data['gridnumber'].unique())\n",
    "    gridnumbers_valid = gridnumbers.sample(n=grid_no, random_state=random_state)\n",
    "    \n",
    "    data_valid = data_select[data_select['gridnumber'].isin(gridnumbers_valid)]\n",
    "    data_train = data[~data['gridnumber'].isin(gridnumbers_valid)]\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['unique_id', 'selected', 'gridnumber', 'name', 'geometry']\n",
    "    data_train = data_train.drop(columns=[col for col in columns_to_drop if col in data_train.columns], errors='ignore')\n",
    "    data_valid = data_valid.drop(columns=[col for col in columns_to_drop if col in data_valid.columns], errors='ignore')\n",
    "\n",
    "    # Ensure ancient is 0 where terrace is 0\n",
    "    data_train.loc[data_train['terrace'] == 0, 'ancient'] = 0\n",
    "    data_valid.loc[data_valid['terrace'] == 0, 'ancient'] = 0\n",
    "    \n",
    "    data_train = data_train.dropna(subset=['ancient'])\n",
    "    data_valid = data_valid.dropna(subset=['ancient'])\n",
    "\n",
    "    if landcover:\n",
    "        data_train['majority_landcover'] = data_train['majority_landcover'].astype(str)\n",
    "        data_valid['majority_landcover'] = data_valid['majority_landcover'].astype(str)\n",
    "\n",
    "    print(f\"Training samples: {data_train.shape[0]}, Validation samples: {data_valid.shape[0]}\")\n",
    "    print(f\"Validation percentage: {round(data_valid.shape[0]*100/(data_train.shape[0]+data_valid.shape[0]), 2)}%\")\n",
    "    print(\"\\nClass distribution (terrace):\")\n",
    "    print(\"Train:\", data_train['terrace'].value_counts().to_dict())\n",
    "    print(\"Valid:\", data_valid['terrace'].value_counts().to_dict())\n",
    "\n",
    "    return data_train, data_valid\n",
    "\n",
    "\n",
    "# Load and split data\n",
    "file_path = \"C:/Users/u0148406/OneDrive - KU Leuven/PhD KUL/TerraceDetection/Cyprus_large/Cyprus_only_train_polysanc.gpkg\"\n",
    "data = gpd.read_file(file_path)\n",
    "\n",
    "data_train_cyprMatch, data_valid_cyprMatch = train_test_grid(\n",
    "    data, percentage_validation=0.2, random_state=22, landcover=True\n",
    ")\n",
    "\n",
    "# Prepare binary classification data (drop 'ancient' column)\n",
    "data_train_cyprMatch1 = data_train_cyprMatch.drop(columns=['ancient'])\n",
    "data_valid_cyprMatch1 = data_valid_cyprMatch.drop(columns=['ancient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Binary Classification - Terrace Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train binary terrace detection model\n",
    "label = 'terrace'\n",
    "problem_type = 'binary'\n",
    "eval_metric = 'mcc'\n",
    "time_limit = 18000\n",
    "path_binary = 'C:/Workdir/test_autogluon/model_CyprusSENtrain_rs22matchBEST'\n",
    "\n",
    "excluded_model_types = ['RF', 'XT', 'KNN', 'XGB', 'GBM']  # Keep NN models and CatBoost\n",
    "\n",
    "predictor_binary = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type=problem_type,\n",
    "    eval_metric=eval_metric,\n",
    "    path=path_binary,\n",
    ").fit(\n",
    "    train_data=data_train_cyprMatch1,\n",
    "    excluded_model_types=excluded_model_types,\n",
    "    presets='best_quality',\n",
    "    time_limit=time_limit\n",
    ")\n",
    "\n",
    "# Evaluate performance\n",
    "performance = predictor_binary.evaluate(data_valid_cyprMatch1, decision_threshold=0.5)\n",
    "leaderboard = predictor_binary.leaderboard(data_valid_cyprMatch1, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'])\n",
    "\n",
    "print(\"Performance:\", performance)\n",
    "print(\"\\nLeaderboard:\\n\", leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained binary model\n",
    "path_binary = 'C:/Workdir/test_autogluon/model_CyprusSENtrain_rs22matchBEST'\n",
    "predictor_binary = TabularPredictor.load(path_binary)\n",
    "\n",
    "# Evaluate and save leaderboard\n",
    "performance = predictor_binary.evaluate(data_valid_cyprMatch1, decision_threshold=0.5)\n",
    "leaderboard = predictor_binary.leaderboard(data_valid_cyprMatch1, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'])\n",
    "\n",
    "print(\"Performance:\", performance)\n",
    "print(\"\\nLeaderboard:\\n\", leaderboard)\n",
    "\n",
    "leaderboard_path = 'D:/Cyprus_paper_data/model_eval_autogluon/model_CyprusSENtrain_rs22matchBEST_leaderboard.csv'\n",
    "leaderboard.to_csv(leaderboard_path)\n",
    "print(f\"\\nLeaderboard saved to {leaderboard_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimal Threshold Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(predicted_probabilities, true_labels, target_total):\n",
    "    \"\"\"Find threshold where TP + FP = target_total\"\"\"\n",
    "    sorted_thresholds = sorted(set(predicted_probabilities), reverse=True)\n",
    "    \n",
    "    for threshold in sorted_thresholds:\n",
    "        predictions = (predicted_probabilities >= threshold).astype(int)\n",
    "        TP = sum((predictions == 1) & (true_labels == 1))\n",
    "        FP = sum((predictions == 1) & (true_labels == 0))\n",
    "        FN = sum((predictions == 0) & (true_labels == 1))\n",
    "        TN = sum((predictions == 0) & (true_labels == 0))\n",
    "        \n",
    "        if TP + FP == target_total:\n",
    "            return threshold, TP, FP, FN, TN\n",
    "    \n",
    "    return None, None, None, None, None\n",
    "\n",
    "\n",
    "# Load model\n",
    "path_binary = 'C:/Workdir/test_autogluon/model_CyprusSENtrain_rs22matchBEST'\n",
    "predictor_binary = TabularPredictor.load(path_binary)\n",
    "\n",
    "# Get predictions\n",
    "label_column = 'terrace'\n",
    "true_labels = data_valid_cyprMatch[label_column]\n",
    "predicted_probabilities = predictor_binary.predict_proba(data_valid_cyprMatch, as_pandas=False)[:, 1]\n",
    "\n",
    "# Calculate PR and ROC metrics\n",
    "precision, recall, thresholds_pr = precision_recall_curve(true_labels, predicted_probabilities)\n",
    "fpr, tpr, thresholds_roc = roc_curve(true_labels, predicted_probabilities)\n",
    "auc_pr = auc(recall, precision)\n",
    "auc_roc = roc_auc_score(true_labels, predicted_probabilities)\n",
    "\n",
    "# Find optimal threshold\n",
    "target_total = true_labels.sum()\n",
    "optimal_threshold, TP, FP, FN, TN = find_optimal_threshold(predicted_probabilities, true_labels, target_total)\n",
    "\n",
    "if optimal_threshold is not None:\n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "    print(f\"TP: {TP}, FP: {FP}, FN: {FN}, TN: {TN}\")\n",
    "    print(f\"Total TP + FP: {TP + FP} (Target: {target_total})\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}, AUC-ROC: {auc_roc:.4f}\")\n",
    "else:\n",
    "    print(\"No optimal threshold found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate metrics across threshold range\n",
    "thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "\n",
    "metrics_list = []\n",
    "for threshold in thresholds:\n",
    "    predictions = predictor_binary.predict(data_valid_cyprMatch1, as_pandas=False, decision_threshold=threshold)\n",
    "    \n",
    "    metrics_list.append({\n",
    "        'threshold': threshold,\n",
    "        'precision': precision_score(true_labels, predictions, zero_division=0),\n",
    "        'recall': recall_score(true_labels, predictions),\n",
    "        'f1': f1_score(true_labels, predictions),\n",
    "        'accuracy': accuracy_score(true_labels, predictions),\n",
    "        'balanced_accuracy': balanced_accuracy_score(true_labels, predictions),\n",
    "        'mcc': matthews_corrcoef(true_labels, predictions)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "print(metrics_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare optimal vs default threshold\n",
    "optimal_threshold = 0.6707\n",
    "default_threshold = 0.5\n",
    "\n",
    "for thresh, name in [(optimal_threshold, \"Optimal\"), (default_threshold, \"Default\")]:\n",
    "    predictions = predictor_binary.predict(data_valid_cyprMatch1, as_pandas=False, decision_threshold=thresh)\n",
    "    \n",
    "    print(f\"\\n{name} Threshold: {thresh:.4f}\")\n",
    "    print(f\"  Precision:        {precision_score(true_labels, predictions, zero_division=0):.4f}\")\n",
    "    print(f\"  Recall:           {recall_score(true_labels, predictions):.4f}\")\n",
    "    print(f\"  F1-Score:         {f1_score(true_labels, predictions):.4f}\")\n",
    "    print(f\"  Accuracy:         {accuracy_score(true_labels, predictions):.4f}\")\n",
    "    print(f\"  Balanced Acc:     {balanced_accuracy_score(true_labels, predictions):.4f}\")\n",
    "    print(f\"  MCC:              {matthews_corrcoef(true_labels, predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multiclass Classification - Terrace Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for multiclass classification (only terraces)\n",
    "train_data_terrace = data_train_cyprMatch[data_train_cyprMatch['terrace'] == 1].drop(columns=['terrace'])\n",
    "valid_data_terrace = data_valid_cyprMatch[data_valid_cyprMatch['terrace'] == 1].drop(columns=['terrace'])\n",
    "\n",
    "print(f\"Training terraces: {train_data_terrace.shape[0]}, Validation terraces: {valid_data_terrace.shape[0]}\")\n",
    "print(\"\\nClass distribution (ancient):\")\n",
    "print(\"Train:\", train_data_terrace['ancient'].value_counts().to_dict())\n",
    "print(\"Valid:\", valid_data_terrace['ancient'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiclass terrace type model\n",
    "label = 'ancient'\n",
    "problem_type = 'multiclass'\n",
    "eval_metric = 'mcc'\n",
    "time_limit = 15000\n",
    "path_multiclass = 'C:/Workdir/test_autogluon/model_CyprusMultinewBEST'\n",
    "\n",
    "excluded_model_types = ['RF', 'XT', 'KNN', 'XGB', 'GBM']\n",
    "\n",
    "predictor_multiclass = TabularPredictor(\n",
    "    label=label,\n",
    "    problem_type=problem_type,\n",
    "    eval_metric=eval_metric,\n",
    "    path=path_multiclass,\n",
    ").fit(\n",
    "    train_data=train_data_terrace,\n",
    "    excluded_model_types=excluded_model_types,\n",
    "    presets='best_quality',\n",
    "    time_limit=time_limit\n",
    ")\n",
    "\n",
    "# Evaluate performance\n",
    "performance = predictor_multiclass.evaluate(valid_data_terrace)\n",
    "leaderboard = predictor_multiclass.leaderboard(valid_data_terrace, extra_metrics=['accuracy', 'balanced_accuracy', 'log_loss'])\n",
    "\n",
    "print(\"Performance:\", performance)\n",
    "print(\"\\nLeaderboard:\\n\", leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Permutation Feature Importance (PFI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both models\n",
    "path_binary = 'C:/Workdir/test_autogluon/model_CyprusSENtrain_rs22matchBEST'\n",
    "path_multiclass = 'C:/Workdir/test_autogluon/model_CyprusMultinewBEST'\n",
    "\n",
    "predictor_terrace = TabularPredictor.load(path_binary)\n",
    "predictor_ancient = TabularPredictor.load(path_multiclass)\n",
    "\n",
    "# Compute feature importance (PFI with permutation shuffling)\n",
    "print(\"Computing feature importance for binary terrace model...\")\n",
    "feature_importance_terrace = predictor_terrace.feature_importance(\n",
    "    data_valid_cyprMatch1, \n",
    "    num_shuffle_sets=10, \n",
    "    confidence_level=0.95\n",
    ")\n",
    "\n",
    "print(\"Computing feature importance for multiclass terrace type model...\")\n",
    "feature_importance_ancient = predictor_ancient.feature_importance(\n",
    "    valid_data_terrace, \n",
    "    num_shuffle_sets=10, \n",
    "    confidence_level=0.95\n",
    ")\n",
    "\n",
    "# Display and save results\n",
    "print(\"\\n=== Feature Importance - Binary Terrace Detection ===\")\n",
    "print(feature_importance_terrace)\n",
    "feature_importance_terrace.to_csv('E:/Cyprus_paper_data/figures/ModelImpFeatTerrace_feat.csv')\n",
    "\n",
    "print(\"\\n=== Feature Importance - Multiclass Terrace Type ===\")\n",
    "print(feature_importance_ancient)\n",
    "feature_importance_ancient.to_csv('E:/Cyprus_paper_data/figures/ModelImpFeatAncient_feat.csv')\n",
    "\n",
    "print(\"\\nâœ“ Feature importance analysis complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
