{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyprus Terrace Detection - Model Inference\n",
    "Apply trained models to predict terraces across Cyprus territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import glob\n",
    "import re\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Load trained models\n",
    "predictor_terrace = TabularPredictor.load('C:/Workdir/test_autogluon/model_CyprusSENtrain_rs22matchBEST')\n",
    "predictor_ancient = TabularPredictor.load('C:/Workdir/test_autogluon/model_CyprusMultinewBEST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all input GPKG files\n",
    "folder_files = \"E:/Cyprus_paper_data/grid_all_polysSen\"\n",
    "all_files_paths = glob.glob(folder_files + \"/*.gpkg\")\n",
    "\n",
    "print(f\"Total files found: {len(all_files_paths)}\")\n",
    "\n",
    "# Optional: Filter specific files if needed\n",
    "# pattern = re.compile(r\"_([1-9]|[1-4][0-9]|5[0-6])_stats\")\n",
    "# selected_files = [file for file in all_files_paths if pattern.search(file)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Two-Stage Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_models_to_gpkg(gpkg_path, output_dir):\n",
    "    \"\"\"\n",
    "    Two-stage prediction: (1) Binary terrace detection, (2) Multiclass terrace type.\n",
    "    Applies both thresholds (0.5 and 0.67) and saves predictions with original labels.\n",
    "    \"\"\"\n",
    "    # Load GeoPackage\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "    \n",
    "    # Store original columns\n",
    "    geometry_col = gdf['geometry']\n",
    "    terrace_col = gdf['terrace'] if 'terrace' in gdf.columns else None\n",
    "    ancient_col = gdf['ancient'] if 'ancient' in gdf.columns else None\n",
    "    \n",
    "    # Drop non-feature columns\n",
    "    gdf = gdf.drop(columns=['terrace', 'ancient', 'geometry', 'name', 'gridnumber', 'PXLVAL', 'Selected'], errors='ignore')\n",
    "    \n",
    "    # Stage 1: Binary terrace detection\n",
    "    predictions_terrace = predictor_terrace.predict_proba(gdf)\n",
    "    gdf['terrace_prob'] = predictions_terrace.iloc[:, 1]\n",
    "    gdf['terrace_binary_0.5'] = (gdf['terrace_prob'] >= 0.5).astype(int)\n",
    "    gdf['terrace_binary_0.67'] = (gdf['terrace_prob'] >= 0.6707).astype(int)\n",
    "    \n",
    "    # Override predictions with ground truth if available (for training data)\n",
    "    if terrace_col is not None:\n",
    "        mask_terrace = (terrace_col == 1) & (gdf['terrace_prob'] < 0.6707)\n",
    "        gdf.loc[mask_terrace, ['terrace_binary_0.67', 'terrace_binary_0.5', 'terrace_prob']] = [1, 1, 0.8]\n",
    "        \n",
    "        mask_non_terrace = (terrace_col == 0) & (gdf['terrace_prob'] > 0.5)\n",
    "        gdf.loc[mask_non_terrace, ['terrace_binary_0.67', 'terrace_binary_0.5', 'terrace_prob']] = [0, 0, 0.49]\n",
    "    \n",
    "    # Stage 2: Multiclass terrace type (only for predicted terraces)\n",
    "    for threshold, col_name in [(0.6707, 'ancient_pred_067'), (0.5, 'ancient_pred_05')]:\n",
    "        gdf_terrace = gdf.loc[gdf[f'terrace_binary_{threshold if threshold == 0.6707 else \"0.5\"}'] == 1].copy()\n",
    "        \n",
    "        if len(gdf_terrace) > 0:\n",
    "            predictions_ancient = predictor_ancient.predict(gdf_terrace)\n",
    "            gdf_terrace[col_name] = predictions_ancient\n",
    "            \n",
    "            # Override with ground truth if available\n",
    "            if ancient_col is not None:\n",
    "                gdf_terrace.loc[ancient_col.notnull(), col_name] = ancient_col.loc[ancient_col.notnull()]\n",
    "            \n",
    "            gdf = gdf.merge(gdf_terrace[[col_name]], left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Restore original columns\n",
    "    gdf['geometry'] = geometry_col\n",
    "    if terrace_col is not None:\n",
    "        gdf['terrace_labeltrue'] = terrace_col\n",
    "    if ancient_col is not None:\n",
    "        gdf['ancient_labeltrue'] = ancient_col\n",
    "    \n",
    "    # Save predictions\n",
    "    gdf = gpd.GeoDataFrame(gdf)\n",
    "    output_path = os.path.join(output_dir, os.path.splitext(os.path.basename(gpkg_path))[0] + \"_pred.gpkg\")\n",
    "    gdf.to_file(output_path, driver='GPKG')\n",
    "    \n",
    "    print(f\"✓ Processed: {os.path.basename(gpkg_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "output_folder = \"E:/Cyprus_paper_data/predictionsSENnew\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Single file test\n",
    "print(\"Testing on single file...\")\n",
    "apply_models_to_gpkg(all_files_paths[0], output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing for all files\n",
    "num_cores = multiprocessing.cpu_count() - 8\n",
    "\n",
    "def process_polygon(polygon_file):\n",
    "    apply_models_to_gpkg(polygon_file, output_folder)\n",
    "\n",
    "print(f\"Processing {len(all_files_paths)} files using {num_cores} cores...\")\n",
    "Parallel(n_jobs=num_cores)(delayed(process_polygon)(file) for file in all_files_paths)\n",
    "\n",
    "print(f\"\\n✓ All predictions saved to: {output_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
